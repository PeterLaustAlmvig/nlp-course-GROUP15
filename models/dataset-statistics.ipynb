{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409756f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: fastparquet in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (2024.11.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: fsspec in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from fastparquet) (2025.9.0)\n",
      "Requirement already satisfied: packaging in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xk84vl/Documents/Repos/nlp-course-GROUP15/group-env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa0bf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 15343, Validation size: 3011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'train.parquet', 'validation': 'validation.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"train\"], engine='fastparquet')\n",
    "df_val = pd.read_parquet(\"hf://datasets/coastalcph/tydi_xor_rc/\" + splits[\"validation\"], engine='fastparquet')\n",
    "print(f\"Train size: {len(df_train)}, Validation size: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8935b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>lang</th>\n",
       "      <th>answerable</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_inlang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...</td>\n",
       "      <td>WikiLeaks () is an international non-profit or...</td>\n",
       "      <td>bn</td>\n",
       "      <td>True</td>\n",
       "      <td>182</td>\n",
       "      <td>2006</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?</td>\n",
       "      <td>The war in Europe concluded with an invasion o...</td>\n",
       "      <td>bn</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...</td>\n",
       "      <td>Same-sex marriage in the United States expande...</td>\n",
       "      <td>bn</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...</td>\n",
       "      <td>The exact number of Arab casualties is unknown...</td>\n",
       "      <td>bn</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>unknown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?</td>\n",
       "      <td>As Thomas Hall (2000) notes, \"The Sung Empire ...</td>\n",
       "      <td>bn</td>\n",
       "      <td>True</td>\n",
       "      <td>1219</td>\n",
       "      <td>17th century</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ...   \n",
       "1           দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ পরাজিত হয় ?   \n",
       "2  মার্কিন যুক্তরাষ্ট্রের সংবিধান অনুযায়ী মার্কিন...   \n",
       "3  আরব-ইসরায়েলি যুদ্ধে আরবের মোট কয়জন সৈন্যের মৃ...   \n",
       "4          বিশ্বে প্রথম পুঁজিবাদী সমাজ কবে গড়ে ওঠে ?   \n",
       "\n",
       "                                             context lang  answerable  \\\n",
       "0  WikiLeaks () is an international non-profit or...   bn        True   \n",
       "1  The war in Europe concluded with an invasion o...   bn        True   \n",
       "2  Same-sex marriage in the United States expande...   bn       False   \n",
       "3  The exact number of Arab casualties is unknown...   bn        True   \n",
       "4  As Thomas Hall (2000) notes, \"The Sung Empire ...   bn        True   \n",
       "\n",
       "   answer_start        answer answer_inlang  \n",
       "0           182          2006          None  \n",
       "1            48       Germany          None  \n",
       "2            -1            no          None  \n",
       "3            39       unknown          None  \n",
       "4          1219  17th century          None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527a66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation sets into new dataframes for ar, ko and te based on the lang column\n",
    "# Test sets\n",
    "df_train_ar = df_train[df_train['lang'] == 'ar']\n",
    "df_train_ko = df_train[df_train['lang'] == 'ko']\n",
    "df_train_te = df_train[df_train['lang'] == 'te']\n",
    "\n",
    "# Validation sets\n",
    "df_val_ar = df_val[df_val['lang'] == 'ar']\n",
    "df_val_ko = df_val[df_val['lang'] == 'ko']\n",
    "df_val_te = df_val[df_val['lang'] == 'te']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c30d9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of words and counting occurrences\n",
    "import unicodedata as ud\n",
    "from nltk import word_tokenize\n",
    "    \n",
    "def tokenize_question(question):\n",
    "    # Remove all punctuation characters, keeping in mind that arabic is written from right to left\n",
    "    question = ''.join([char for char in question if not ud.category(char).startswith('P')])\n",
    "    # Tokenize the question into words\n",
    "    words = word_tokenize(question)\n",
    "    return words\n",
    "\n",
    "def word_occurrence(questions):\n",
    "    word_count = {}\n",
    "    for question in questions:\n",
    "        words = tokenize_question(question)\n",
    "        for word in words:\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "    return word_count\n",
    "\n",
    "# Get word occurrence for each language in train set\n",
    "word_count_ar = word_occurrence(df_train_ar['question'].tolist())\n",
    "word_count_ko = word_occurrence(df_train_ko['question'].tolist())\n",
    "word_count_te = word_occurrence(df_train_te['question'].tolist())\n",
    "\n",
    "# Get word occurrence for each language in validation set\n",
    "word_count_ar_val = word_occurrence(df_val_ar['question'].tolist())\n",
    "word_count_ko_val = word_occurrence(df_val_ko['question'].tolist())\n",
    "word_count_te_val = word_occurrence(df_val_te['question'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5059da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the facebook/nllb-200-distilled-600M model to translate a word from a given language to English\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "target_lang = \"eng_Latn\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, tgt_lang=target_lang)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def translate_word(word, src_lang):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    encoded = tokenizer(word, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(encoded['input_ids'], forced_bos_token_id=tokenizer.convert_tokens_to_ids(target_lang))\n",
    "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    return translation\n",
    "\n",
    "def translate_word_list(word_list, src_lang):\n",
    "    translations = {}\n",
    "    for word in word_list:\n",
    "        translation = translate_word(word, src_lang)\n",
    "        translations[word] = translation\n",
    "    return translations\n",
    "\n",
    "most_common_words_ar = [word for word, _ in sorted(word_count_ar.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_ar = translate_word_list(most_common_words_ar, 'arb_Arab')\n",
    "most_common_words_ar_val = [word for word, _ in sorted(word_count_ar_val.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_ar_val = translate_word_list(most_common_words_ar_val, 'arb_Arab')\n",
    "\n",
    "most_common_words_ko = [word for word, _ in sorted(word_count_ko.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_ko = translate_word_list(most_common_words_ko, 'kor_Hang')\n",
    "most_common_words_ko_val = [word for word, _ in sorted(word_count_ko_val.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_ko_val = translate_word_list(most_common_words_ko_val, 'kor_Hang')\n",
    "\n",
    "most_common_words_te = [word for word, _ in sorted(word_count_te.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_te = translate_word_list(most_common_words_te, 'tel_Telu')\n",
    "most_common_words_te_val = [word for word, _ in sorted(word_count_te_val.items(), key=lambda x: x[1], reverse=True)[:5]]\n",
    "translations_te_val = translate_word_list(most_common_words_te_val, 'tel_Telu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3931bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example question Arabic: متى تدخلت روسيا في  الحرب الأهلية السورية؟\n",
      "\n",
      "Training Data Statistics for Arabic:\n",
      "Total size (ar): 2558\n",
      "Count of unique words (ar): 5401\n",
      "Count of all words (ar): 16191\n",
      "Average number of words per question (ar): 6.3295543393276\n",
      "5 most common words (ar): [('في', 593), ('من', 586), ('متى', 535), ('ما', 442), ('هو', 349)]\n",
      "Translations of the 5 most common words (ar): {'في': 'In the', 'من': 'Who ?', 'متى': 'When ?', 'ما': 'What ?', 'هو': 'It is .'}\n",
      "\n",
      "Validation Data Statistics for Arabic:\n",
      "Total size (ar): 415\n",
      "Count of unique words (ar): 1180\n",
      "Count of all words (ar): 2617\n",
      "Average number of words per question (ar): 6.306024096385542\n",
      "5 most common words (ar): [('من', 113), ('في', 90), ('ما', 81), ('هو', 66), ('متى', 65)]\n",
      "Translations of the 5 most common words (ar): {'من': 'Who ?', 'في': 'In the', 'ما': 'What ?', 'هو': 'It is .', 'متى': 'When ?'}\n"
     ]
    }
   ],
   "source": [
    "# Example question in Arabic\n",
    "print(\"Example question Arabic:\", df_train_ar.iloc[0]['question'])\n",
    "\n",
    "# Training dataset statistics for Arabic\n",
    "print(\"\\nTraining Data Statistics for Arabic:\")\n",
    "print(f\"Total size (ar): {len(df_train_ar)}\")\n",
    "print(f\"Count of unique words (ar): {len(word_count_ar)}\")\n",
    "print(f\"Count of all words (ar): {sum(word_count_ar.values())}\")\n",
    "print(f\"Average number of words per question (ar): {sum(word_count_ar.values()) / len(df_train_ar)}\")\n",
    "print(f\"5 most common words (ar):\", sorted(word_count_ar.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (ar):\", translations_ar)\n",
    "\n",
    "# Validation dataset statistics for Arabic\n",
    "print(\"\\nValidation Data Statistics for Arabic:\")\n",
    "print(f\"Total size (ar): {len(df_val_ar)}\")\n",
    "print(f\"Count of unique words (ar): {len(word_count_ar_val)}\")\n",
    "print(f\"Count of all words (ar): {sum(word_count_ar_val.values())}\")\n",
    "print(f\"Average number of words per question (ar): {sum(word_count_ar_val.values()) / len(df_val_ar)}\")\n",
    "print(f\"5 most common words (ar):\", sorted(word_count_ar_val.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (ar):\", translations_ar_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b543c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example question Korean: 30년 전쟁의 승자는 누구인가?\n",
      "\n",
      "Training Data Statistics for Korean:\n",
      "Total size (ko): 2422\n",
      "Count of unique words (ko): 4396\n",
      "Count of all words (ko): 11846\n",
      "Average number of words per question (ko): 4.8909991742361685\n",
      "5 most common words (ko): [('가장', 527), ('무엇인가', 497), ('언제', 336), ('몇', 234), ('어디인가', 228)]\n",
      "Translations of the 5 most common words (ko): {'가장': 'The most', '무엇인가': 'Something.', '언제': 'When?', '몇': 'A few.', '어디인가': 'Where are you?'}\n",
      "\n",
      "Validation Data Statistics for Korean:\n",
      "Total size (ko): 356\n",
      "Count of unique words (ko): 828\n",
      "Count of all words (ko): 1729\n",
      "Average number of words per question (ko): 4.856741573033708\n",
      "5 most common words (ko): [('무엇인가', 75), ('가장', 66), ('언제', 44), ('어디인가', 29), ('큰', 24)]\n",
      "Translations of the 5 most common words (ko): {'무엇인가': 'Something.', '가장': 'The most', '언제': 'When?', '어디인가': 'Where are you?', '큰': 'Big one.'}\n"
     ]
    }
   ],
   "source": [
    "# Example question in Korean\n",
    "print(\"Example question Korean:\", df_train_ko.iloc[0]['question'])\n",
    "\n",
    "# Training dataset statistics for Korean\n",
    "print(\"\\nTraining Data Statistics for Korean:\")\n",
    "print(f\"Total size (ko): {len(df_train_ko)}\")\n",
    "print(f\"Count of unique words (ko): {len(word_count_ko)}\")\n",
    "print(f\"Count of all words (ko): {sum(word_count_ko.values())}\")\n",
    "print(f\"Average number of words per question (ko): {sum(word_count_ko.values()) / len(df_train_ko)}\")\n",
    "print(f\"5 most common words (ko):\", sorted(word_count_ko.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (ko):\", translations_ko)\n",
    "\n",
    "# Validation dataset statistics for Korean\n",
    "print(\"\\nValidation Data Statistics for Korean:\")\n",
    "print(f\"Total size (ko): {len(df_val_ko)}\")\n",
    "print(f\"Count of unique words (ko): {len(word_count_ko_val)}\")\n",
    "print(f\"Count of all words (ko): {sum(word_count_ko_val.values())}\")\n",
    "print(f\"Average number of words per question (ko): {sum(word_count_ko_val.values()) / len(df_val_ko)}\")\n",
    "print(f\"5 most common words (ko):\", sorted(word_count_ko_val.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (ko):\", translations_ko_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0e7556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example question Telugu: ప్రపంచంలో  మొట్టమొదటి దూర విద్య విద్యాలయం ఏ దేశంలో స్థాపించబడింది ?\n",
      "\n",
      "Training Data Statistics for Telugu:\n",
      "Total size (te): 1355\n",
      "Count of unique words (te): 2411\n",
      "Count of all words (te): 7666\n",
      "Average number of words per question (te): 5.657564575645757\n",
      "5 most common words (te): [('ఎవరు', 274), ('ఏది', 192), ('ఎన్ని', 165), ('ఎప్పుడు', 154), ('ఏ', 142)]\n",
      "Translations of the 5 most common words (te): {'ఎవరు': 'Who is it?', 'ఏది': 'What is it?', 'ఎన్ని': 'How many', 'ఎప్పుడు': 'When', 'ఏ': 'No, not at all.'}\n",
      "\n",
      "Validation Data Statistics for Telugu:\n",
      "Total size (te): 384\n",
      "Count of unique words (te): 741\n",
      "Count of all words (te): 2299\n",
      "Average number of words per question (te): 5.986979166666667\n",
      "5 most common words (te): [('ఏ', 92), ('ఏది', 76), ('ఎవరు', 74), ('భారతదేశంలో', 45), ('ఎంత', 40)]\n",
      "Translations of the 5 most common words (te): {'ఏ': 'No, not at all.', 'ఏది': 'What is it?', 'ఎవరు': 'Who is it?', 'భారతదేశంలో': 'In India', 'ఎంత': 'How much'}\n"
     ]
    }
   ],
   "source": [
    "# Example question in Telugu\n",
    "print(\"Example question Telugu:\", df_train_te.iloc[0]['question'])\n",
    "\n",
    "# Training dataset statistics for Telugu\n",
    "print(\"\\nTraining Data Statistics for Telugu:\")\n",
    "print(f\"Total size (te): {len(df_train_te)}\")\n",
    "print(f\"Count of unique words (te): {len(word_count_te)}\")\n",
    "print(f\"Count of all words (te): {sum(word_count_te.values())}\")\n",
    "print(f\"Average number of words per question (te): {sum(word_count_te.values()) / len(df_train_te)}\")\n",
    "print(f\"5 most common words (te):\", sorted(word_count_te.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (te):\", translations_te)\n",
    "\n",
    "# Validation dataset statistics for Telugu\n",
    "print(\"\\nValidation Data Statistics for Telugu:\")\n",
    "print(f\"Total size (te): {len(df_val_te)}\")\n",
    "print(f\"Count of unique words (te): {len(word_count_te_val)}\")\n",
    "print(f\"Count of all words (te): {sum(word_count_te_val.values())}\")\n",
    "print(f\"Average number of words per question (te): {sum(word_count_te_val.values()) / len(df_val_te)}\")\n",
    "print(f\"5 most common words (te):\", sorted(word_count_te_val.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "print(\"Translations of the 5 most common words (te):\", translations_te_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
